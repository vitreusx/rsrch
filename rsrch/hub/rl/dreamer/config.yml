_:
  act: elu
  norm: none
  conv: &conv
    depth: 48
    kernels: [4, 4, 4, 4]
    act: ${_.act}
    norm: ${_.norm}
  conv_t: &conv_t
    depth: ${_.conv.depth}
    kernels: [5, 5, 6, 6]
    act: ${_.act}
    norm: ${_.norm}
  mlp: &mlp
    hidden: 400
    layers: 4
    act: ${_.act}
    norm: ${_.norm}

run:
  prefix: ~
  no_ansi: false
  create_commit: true

repro:
  seed: 42
  determinism: sufficient
device: cuda
compute_dtype: float16
def_step: env_step
debug:
  detect_anomaly: false
profile:
  enabled: false
  schedule: { wait: 5, warmup: 1, active: 3, repeat: 4 }
  functions: [do_opt_step, do_env_step]

env:
  type: atari
  atari:
    env_id: Alien-v5
    screen_size: 64
    frame_skip: 4
    obs_type: grayscale
    noop_max: 30
    fire_reset: true
    term_on_life_loss: false
    time_limit: 108e3
    stack_num: ~

agent:
  train_noise: 0.0
  eval_noise: 0.0
train:
  dataset:
    capacity: 2e6
    batch_size: 16
    slice_len: 50
    subseq_len: [50, 50]
    prioritize_ends: true
    ongoing: false
  val_frac: 0.0
  num_envs: 1
  horizon: 15
val_envs: 4

wm:
  type: dreamer
  dreamer:
    rssm:
      ensemble: 1
      deter_size: 1024
      stoch:
        type: discrete
        num_tokens: 32
        vocab_size: 32
      act: ${_.act}
      norm: ${_.norm}
      hidden_size: 1024
      jit: true
    opt:
      type: adam_w
      lr: 1e-4
      eps: 1e-5
      weight_decay: "${1e-6/lr}"
    kl:
      free: 0.0
      forward: false
      balance: 0.8
      free_avg: true
    reward_fn: tanh
    clip_rew: [-1.0, 1.0]
    coef: {}
    clip_grad: 1.0e2
    encoder:
      type: auto
      box: *mlp
      image: *conv
    decoders:
      obs:
        type: auto
        box:
          <<: [*mlp]
          dist: { type: mse }
        image:
          <<: [*conv_t]
          dist: { type: mse }
      reward:
        type: box
        box:
          <<: [*mlp]
          dist: { type: mse }
      term:
        type: discrete
        discrete: *mlp

ac:
  type: ref
  ref:
    actor: *mlp
    actor_dist:
      type: auto
      beta:
        min_std: 0.1
    critic:
      <<: [*mlp]
      dist: { type: mse }
    target_critic: { every: 100 }
    gamma: 0.99
    gae_lambda: 0.95
    actor_grad: auto
    actor_grad_mix: 0.1
    actor_ent: 2e-3
    coef: {}
    opt:
      type: adam_w
      actor: { lr: 8e-5, weight_decay: "${1e-6/lr}" }
      critic: { lr: 2e-4, weight_decay: "${1e-6/lr}" }
      eps: 1e-5
    clip_grad: 1.0e2
    rew_norm:
      momentum: 1.0
      scale: 1.0
      eps: 1e-8
  sac: ~

stages:
  - env_rollout:
      until: 10e3
      mode: rand
  - train_loop:
      until: 100e6
      tasks:
        - do_opt_step: ~
          every: 5
        - do_env_step

extras:
  discrete_actions: ~
