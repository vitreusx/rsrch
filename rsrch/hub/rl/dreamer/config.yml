_:
  act: elu
  norm: none
  conv: &conv
    depth: 48
    kernels: [4, 4, 4, 4]
    act: ${_.act}
    norm: ${_.norm}
  conv_t: &conv_t
    depth: ${_.conv.depth}
    kernels: [5, 5, 6, 6]
    act: ${_.act}
    norm: ${_.norm}
  mlp: &mlp
    hidden: 400
    layers: 4
    act: ${_.act}
    norm: ${_.norm}

run:
  dir: ~
  interactive: true
  create_commit: true

repro:
  seed: 42
  determinism: sufficient
device: cuda
compute_dtype: float16
def_step: env_step
debug:
  detect_anomaly: false
profile:
  enabled: false
  schedule: { wait: 5, warmup: 1, active: 3, repeat: 4 }
  functions: [do_opt_step, do_env_step]

env:
  type: atari
  atari:
    env_id: Alien
    screen_size: 64
    frame_skip: 4
    obs_type: grayscale
    noop_max: 30
    fire_reset: true
    term_on_life_loss: false
    sticky: true
    time_limit: 108e3
    stack_num: ~

data:
  buffer:
    capacity: 2e6
    batch_size: 16
    slice_len: 50
    subseq_len: [50, 50]
    prioritize_ends: true
    ongoing: false
  dream:
    batch_size: ${data.buffer.batch_size * data.buffer.slice_len}
    horizon: 15
  val_frac: 0.0

train:
  num_envs: 1
  agent_noise: 0.0
val:
  num_envs: 4
  agent_noise: 0.0

wm:
  type: dreamer
  dreamer:
    rssm:
      ensemble: 1
      deter_size: 1024
      stoch:
        type: discrete
        num_tokens: 32
        vocab_size: 32
      act: ${_.act}
      norm: ${_.norm}
      hidden_size: 1024
      jit: true
    opt:
      type: adam_w
      lr: 1e-4
      eps: 1e-5
      weight_decay: "${1e-6/lr}"
    kl:
      free: 0.0
      forward: false
      balance: 0.8
      free_avg: true
    reward_fn: tanh
    clip_rew: [-1.0, 1.0]
    coef: {}
    clip_grad: 1.0e2
    encoder:
      type: auto
      box: *mlp
      image: *conv
    decoders:
      obs:
        type: auto
        box:
          <<: [*mlp]
          dist: { type: mse }
        image:
          <<: [*conv_t]
          dist: { type: mse }
      reward:
        type: box
        box:
          <<: [*mlp]
          dist: { type: mse }
      term:
        type: discrete
        discrete: *mlp

rl:
  type: a2c
  a2c:
    actor:
      encoder:
        type: box
        box: *mlp
      dist:
        type: auto
        beta:
          min_std: 0.1
    critic:
      encoder:
        type: box
        box: *mlp
      dist:
        type: mse
    target_critic: { every: 100 }
    gamma: 0.99
    gae_lambda: 0.95
    actor_grad: auto
    actor_grad_mix: 0.1
    actor_ent: 2e-3
    coef: {}
    opt:
      type: adam_w
      actor: { lr: 8e-5, weight_decay: "${1e-6/lr}" }
      critic: { lr: 2e-4, weight_decay: "${1e-6/lr}" }
      eps: 1e-5
    clip_grad: 1.0e2
    rew_norm:
      momentum: 1.0
      scale: 1.0
      eps: 1e-8
  ppo:
    actor_dist:
      type: auto
      beta:
        min_std: 0.1
    update_epochs: 4
    update_batch: 256
    adv_norm: true
    clip_coeff: 0.1
    clip_vloss: true
    ent_coeff: 1e-2
    vf_coeff: 0.5
    clip_grad: 0.5
    gamma: 0.99
    gae_lambda: 0.95
    opt:
      type: adam_w
      lr: 2.5e-4
      eps: 1e-5
    share_encoder: false

stages:
  - env_rollout:
      until: 10e3
      mode: rand
  - train_loop:
      until: 100e6
      tasks:
        - do_opt_step: ~
          every: 5
        - do_env_step

use_model: true
