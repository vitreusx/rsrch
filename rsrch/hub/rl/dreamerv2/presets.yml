atari:
  wm:
    rssm:
      deter_size: 600
      hidden_size: 600
    opt.lr: 2e-4
    coef: { kl: 0.1, term: 5.0 }
  ac:
    gamma: 0.999
    actor_ent: 1e-3
    opt.actor.lr: 4e-5
    opt.critic.lr: 1e-4
  total: { n: 200e6, of: env_step }
  prefill: { n: 200e3, of: env_step }
  trainer:
    basic.sched: { n: 64, of: env_step }
fast:
  total.n: 10e6
  save_every.n: 1e6
  prefill.n: 100e3
# atari_der:
#   trainer:
#     basic.sched: { n: 32, of: env_step }
# sample:
#   mode: sample
#   sampler:
#     num_samples: 100e3
#     ckpt_path: "runs/dreamerv2/ALE-Pong-v5__2024-07-09_06-39-03/ckpts/env_step=7100004.pth"
#     env_mode: train
#     agent_mode: train
preload:
  dataset.preload: runs/dreamerv2/ALE-Pong-v5__2024-07-09_19-44-05/samples.pkl
